校园搜索

张耀楠 魏知宇

[TOC]

## 爬取数据

### 参数配置

​	我们使用了Heritrix 3.2.0而非ppt中所说的1.X版本进行清华校内页面的爬取。由于版本的不同，配置方法上出现了很大的差异，ppt中所介绍的很多选项都不再存在，最终我们从网上找到了一个xml配置文件格式的介绍，通过xml文件完成了爬虫的参数配置。

### 实际问题

​	在爬取中也出现了一些问题，主要问题是Heritrix在爬取中会越来越慢，在爬取了20万个页面以后的爬取速度甚至只有刚开始运行时的三分之一甚至更低。对于这个问题，我们查找了相关的资料，主要原因是Heritrix使用了多线程来进行页面的爬取，但每一个页面是按照主机来分配线程的（我猜测可能是为了防止对某一主机出现大量的同时访问），导致在后期只有极少几个线程在运行，严重拖慢了效率。

​	由于Heritrix的低耦合特性，一个可行的改进策略是重写线程分配的模块，但我们最终没有采用这一策略，而是通过添加多个初始种子的策略，这样可以保证爬取时能比较均匀地从各个地址同步开始，最终通过近30个url的起始种子，一定程度上改善了这一现象。



## 计算PageRank

### 建立关系图

​	建立了WebNode类记录每个网页节点，WebEdge类记录每条链接关系。

​	首先读取craw.log获取所有抓取的文件。为了得到链接的关系图，需要遍历所有网页文件，使用正则表达式获取所有可能的链接，检查是否在记录中。由于链接可能有多种格式，如：

```
http://tsinghua.edu.cn/index.html
//tsinghua.edu.cn/index.html?page=2
publish/index.html?page=3&id=1
../index.html
```



需要一个比较复杂的正则表达式：

```java
Pattern p = Pattern.compile("[\"\']\\s*(((https?:)?\\/\\/([^\\s\'\"]*?\\.cn))?\\/)?([^\\/\"\'][^\\s\"\']*?)\\.html(\\?([^\\s\"\']*?=[^\\s\"\']*?))?\\s*[\"\']");

```

并且需要处理以"../"开头的路径。

之后建立一条边，从当前节点到目标节点。

### 计算

​	使用之前作业已经用过的算法，参数上alpha取0.15，迭代次数TN取30。 

## 建立索引

### 数据解析

​	数据解析是一个巨型工程，在html之外我们还需要解析doc和pdf两种文件。

​	对于一个html，我们关心其title，text，h1，h2。数据解析程序直接读入整个html，解析出对应内容并缓存即可。

​	对于doc，我们使用poi进行解析，对每个doc文件，数据解析只关心两个内容，即其标题与正文，即仅有title和text，其余各块内容均视为空。标题来自爬虫爬取时的链接名，而内容则是正文中过滤特殊字符后的所有字符。

​	对于pdf，我们使用pdfbox进行解析，与doc类似，数据解析同样只关心title和text，且title来自于爬虫爬取时的链接名，而text来自经过过滤的正文。

### 建立索引

​	在完成了数据解析工作后，就可以进行索引建立了。 

​	我们使用分词工具 和索引工具Lucene 3.5.0进行索引构建。这一部分的代码逻辑基本和当时图片搜索的代码逻辑相同，在数据解析之后我们得到了一个巨型xml文件，再由这个xml文件得到最终的索引即可。这个巨型xml文件涵盖了所有要建立索引的内容的url，title，text等等。Lucene将读入这些部分的内容，将其p视为一个Field，对其进行分词处理并最终建立索引。



## 计算得分 

​	如前所述，对于一个html，我们解析出了，而对于pdf和doc，则只有title和text两个部分。在处理时我们对各个板块的boost处理如下：

​	titleField.setBoost(7);

​	h1Field.setBoost(5);

​	h2Field.setBoost(4);

​	textField.setBoost(3);

​	同时对于整个页面，还有一个基于pageRank的boost，值即为其pageRank的值，这样我们便成功地将索引的得分和pagerank的得分结合在了一起。

​	

## 搜索页面设计

主要利用了bootstrap框架，自行设计了一套显示界面，包含显示标题、显示链接、提供网页跳转和（缓存的）网页快照的功能。